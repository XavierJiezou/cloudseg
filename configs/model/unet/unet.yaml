# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /trainer: gpu
  - override /data: hrc_whu/hrc_whu
  - override /model: unet
  - override /logger: wandb
  - override /callbacks: default

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["hrc_whu", "unet"]

seed: 42

trainer:
  min_epochs: 10
  max_epochs: 10
  gradient_clip_val: 0.5
  devices: 1

data:
  batch_size: 128
  train_val_test_split: [55_000, 5_000, 10_000]
  num_workers: 31
  pin_memory: False
  persistent_workers: False

model:
  in_channels: 3
  out_channels: 7


logger:
  wandb:
    project: "hrc_whu"
    name: "unet"
  aim:
    experiment: "unet"

callbacks:
  model_checkpoint:
    dirpath: ${paths.output_dir}/checkpoints
    filename: "epoch_{epoch:03d}"
    monitor: "val/loss"
    mode: "min"
    save_last: True
    auto_insert_metric_name: False

  early_stopping:
    monitor: "val/loss"
    patience: 100
    mode: "min"